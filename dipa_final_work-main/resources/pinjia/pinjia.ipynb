{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected faces in 46 out of 60 frames.\n",
      "76.67% of all frames have faces detected.\n"
     ]
    }
   ],
   "source": [
    "#没有进行数字图像处理操作前dlib包成功识别到人脸的概率\n",
    "#目前对example_4的识别效果不好，成功识别率只有76.67%\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "# 加载前置人脸检测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 打开视频文件\n",
    "video = cv2.VideoCapture('./data/example_4.avi')\n",
    "\n",
    "# 初始化帧数计数器和识别到的人脸计数器\n",
    "frame_count = 0\n",
    "faces_detected = 0\n",
    "\n",
    "while True:\n",
    "    # 逐帧读取视频\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # 如果读取成功\n",
    "    if ret:\n",
    "        # 转换当前帧为灰度图像\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #对图像进行处理的操作放在这边\n",
    "        # 使用检测器检测人脸\n",
    "        faces = detector(gray)\n",
    "        \n",
    "        # 记录是否检测到人脸\n",
    "        if len(faces) > 0:\n",
    "            faces_detected += 1\n",
    "\n",
    "        # 绘制人脸边框\n",
    "        for face in faces:\n",
    "            x1 = face.left()\n",
    "            y1 = face.top()\n",
    "            x2 = face.right()\n",
    "            y2 = face.bottom()\n",
    "            \n",
    "            # 在原始帧上画矩形以标记人脸\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 4)      \n",
    "        # 显示带有标记人脸的帧\n",
    "        cv2.imshow('Frame with Detected Faces', frame)\n",
    "\n",
    "        # 如果按下'q'键，就退出循环\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break  # 如果没有下一帧了，退出循环\n",
    "    frame_count += 1\n",
    "\n",
    "# 释放视频文件和销毁所有窗口\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 打印视频中检测到人脸的帧数占总帧数的比例\n",
    "print(f'Detected faces in {faces_detected} out of {frame_count} frames.')\n",
    "print(f'{(faces_detected / frame_count) * 100:.2f}% of all frames have faces detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected faces in 52 out of 60 frames.\n",
      "86.67% of all frames have faces detected.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# 加载前置人脸检测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 打开视频文件\n",
    "video = cv2.VideoCapture('./data/example_4.avi')\n",
    "\n",
    "# 初始化帧数计数器和识别到的人脸计数器\n",
    "frame_count = 0\n",
    "faces_detected = 0\n",
    "\n",
    "while True:\n",
    "    # 逐帧读取视频\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # 如果读取成功\n",
    "    if ret:\n",
    "        # 转换当前帧为灰度图像\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 自适应直方图均衡化\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        clahe_gray = clahe.apply(gray)\n",
    "\n",
    "        # 对CLAHE结果应用高斯模糊，以减少噪声\n",
    "        blur_sigma = 2  # 高斯核的标准偏差，在不同图像上可能需要调整88.83\n",
    "\n",
    "        gaussian_blur = cv2.GaussianBlur(clahe_gray, (5, 5), blur_sigma)\n",
    "\n",
    "        # 然后应用拉普拉斯算子进行边缘检测\n",
    "        ddepth = cv2.CV_16S\n",
    "        kernel_size = 3\n",
    "        laplacian = cv2.Laplacian(gaussian_blur, ddepth, ksize=kernel_size)\n",
    "        laplacian_abs = cv2.convertScaleAbs(laplacian)\n",
    "\n",
    "        # 将增强的边缘与原CLAHE图像叠加\n",
    "        alpha = 0.7\n",
    "        beta = 1 - alpha\n",
    "        enhanced_edges = cv2.addWeighted(clahe_gray, alpha, laplacian_abs, beta, 0)\n",
    "\n",
    "\n",
    "        # 使用检测器检测人脸\n",
    "        faces = detector(enhanced_edges)\n",
    "        \n",
    "        # 记录是否检测到人脸\n",
    "        if len(faces) > 0:\n",
    "            faces_detected += 1\n",
    "\n",
    "        # 绘制人脸边框\n",
    "        for face in faces:\n",
    "            x1 = face.left()\n",
    "            y1 = face.top()\n",
    "            x2 = face.right()\n",
    "            y2 = face.bottom()\n",
    "            \n",
    "            # 在原始帧上画矩形以标记人脸\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "        \n",
    "        # 显示带有标记人脸的帧\n",
    "        cv2.imshow('Frame with Detected Faces', frame)\n",
    "\n",
    "        # 如果按下'q'键，就退出循环\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break  # 如果没有下一帧了，退出循环\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# 释放视频文件和销毁所有窗口\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 打印视频中检测到人脸的帧数占总帧数的比例\n",
    "print(f'Detected faces in {faces_detected} out of {frame_count} frames.')\n",
    "print(f'{(faces_detected / frame_count) * 100:.2f}% of all frames have faces detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected faces in 56 out of 60 frames.\n",
      "93.33% of all frames have faces detected.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# 加载前置人脸检测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 打开视频文件\n",
    "video = cv2.VideoCapture('./data/example_4.avi')\n",
    "\n",
    "# 初始化帧数计数器和识别到的人脸计数器\n",
    "frame_count = 0\n",
    "faces_detected = 0\n",
    "\n",
    "while True:\n",
    "    # 逐帧读取视频\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # 如果读取成功\n",
    "    if ret:\n",
    "        # 转换当前帧为灰度图像\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 自适应直方图均衡化\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        clahe_gray = clahe.apply(gray)\n",
    "\n",
    "        # 对CLAHE结果应用高斯模糊，以减少噪声\n",
    "        blur_sigma = 2  # 高斯核的标准偏差，在不同图像上可能需要调整\n",
    "\n",
    "        gaussian_blur = cv2.GaussianBlur(clahe_gray, (5, 5), blur_sigma)\n",
    "\n",
    "   \n",
    "        # 使用Canny算法进行边缘检测\n",
    "        low_threshold = 50  # Canny边缘检测的低阈值\n",
    "        high_threshold = 150  # Canny边缘检测的高阈值\n",
    "        canny_edges = cv2.Canny(gaussian_blur, low_threshold, high_threshold)\n",
    "\n",
    "        # 将Canny边缘图像转换为原图像空间的大小以便叠加\n",
    "        canny_edges_colored = cv2.cvtColor(canny_edges, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # 将增强的边缘与原CLAHE图像叠加\n",
    "        alpha = 0.8\n",
    "        beta = 1 - alpha\n",
    "        enhanced_edges = cv2.addWeighted(clahe_gray, alpha, canny_edges, beta, 0)\n",
    "        \n",
    "\n",
    "        # 使用检测器检测人脸\n",
    "        faces = detector(enhanced_edges)\n",
    "        \n",
    "        # 记录是否检测到人脸\n",
    "        if len(faces) > 0:\n",
    "            faces_detected += 1\n",
    "\n",
    "        # 绘制人脸边框\n",
    "        for face in faces:\n",
    "            x1 = face.left()\n",
    "            y1 = face.top()\n",
    "            x2 = face.right()\n",
    "            y2 = face.bottom()\n",
    "            \n",
    "            # 在原始帧上画矩形以标记人脸\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "        \n",
    "        # 显示带有标记人脸的帧\n",
    "        cv2.imshow('Frame with Detected Faces', frame)\n",
    "\n",
    "        # 如果按下'q'键，就退出循环\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break  # 如果没有下一帧了，退出循环\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# 释放视频文件和销毁所有窗口\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 打印视频中检测到人脸的帧数占总帧数的比例\n",
    "print(f'Detected faces in {faces_detected} out of {frame_count} frames.')\n",
    "print(f'{(faces_detected / frame_count) * 100:.2f}% of all frames have faces detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected faces in 58 out of 60 frames.\n",
      "96.67% of all frames have faces detected.\n"
     ]
    }
   ],
   "source": [
    "#在canny的基础加上形态学操作，成功识别率达到96.67%\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# 加载前置人脸检测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 打开视频文件\n",
    "video = cv2.VideoCapture('./data/example_4.avi')\n",
    "\n",
    "# 初始化帧数计数器和识别到的人脸计数器\n",
    "frame_count = 0\n",
    "faces_detected = 0\n",
    "\n",
    "while True:\n",
    "    # 逐帧读取视频\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # 如果读取成功\n",
    "    if ret:\n",
    "        # 转换当前帧为灰度图像\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # 自适应直方图均衡化\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        clahe_gray = clahe.apply(gray)\n",
    "\n",
    "        # 对CLAHE结果应用高斯模糊，以减少噪声\n",
    "        blur_sigma = 2  # 高斯核的标准偏差，在不同图像上可能需要调整\n",
    "        gaussian_blur = cv2.GaussianBlur(clahe_gray, (5, 5), blur_sigma)\n",
    "\n",
    "        # 使用Canny算法进行边缘检测\n",
    "        low_threshold = 50  # Canny边缘检测的低阈值\n",
    "        high_threshold = 150  # Canny边缘检测的高阈值\n",
    "        canny_edges = cv2.Canny(gaussian_blur, low_threshold, high_threshold)\n",
    "\n",
    "        # 进行形态学变换 - 闭操作\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        closing = cv2.morphologyEx(canny_edges, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # 将闭操作后的边缘与原CLAHE图像进行叠加\n",
    "        # 转换闭操作后的边缘图像的数据类型，使其可以与原图像进行加权叠加\n",
    "        closing_for_combination = cv2.convertScaleAbs(closing)\n",
    "        enhanced_edges = cv2.addWeighted(clahe_gray, 0.7, closing_for_combination, 0.3, 0)\n",
    "        \n",
    "\n",
    "        # 使用检测器检测人脸\n",
    "        faces = detector(enhanced_edges)\n",
    "        \n",
    "        # 记录是否检测到人脸\n",
    "        if len(faces) > 0:\n",
    "            faces_detected += 1\n",
    "\n",
    "        # 绘制人脸边框\n",
    "        for face in faces:\n",
    "            x1 = face.left()\n",
    "            y1 = face.top()\n",
    "            x2 = face.right()\n",
    "            y2 = face.bottom()\n",
    "            \n",
    "            # 在原始帧上画矩形以标记人脸\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "        \n",
    "        # 显示带有标记人脸的帧\n",
    "        cv2.imshow('Frame with Detected Faces', frame)\n",
    "\n",
    "        # 如果按下'q'键，就退出循环\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break  # 如果没有下一帧了，退出循环\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# 释放视频文件和销毁所有窗口\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 打印视频中检测到人脸的帧数占总帧数的比例\n",
    "print(f'Detected faces in {faces_detected} out of {frame_count} frames.')\n",
    "print(f'{(faces_detected / frame_count) * 100:.2f}% of all frames have faces detected.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_7_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
